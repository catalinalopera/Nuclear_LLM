Purpose of Project:
The primary goal of the project is to explore and evaluate different data generation methodologies for fine-tuning a large language model (LLM). The aim is to determine which methodology yields the best performance based on specific evaluation metrics.

Objectives:

• Explore various data generation methodologies for the fine-tuning of LLMs

• Evaluate the fine-tuned LLMs using specific performance metrics

• Determine the best data generation methodologies for fine-tuning an LLM

Scope:

• Research available open-source datasets and LLMs

• Develop code to run and fine-tune LLMs

• Generate data using different methodologies for fine-tuning

• Fine-tune the LLM using generated datasets

• Evaluate the performance of the fine-tuned LLMs

Expected Outcomes:

• Working code for automatic data generation for fine-tuning an LLM

• Working code for running and fine-tuning an LLM

• Analysis and comparison of different data generation methodologies

• Fine-tuned LLM models with performance evaluations

• Documentation and reports summarizing the findings and methodologies

Data:

• Use public datasets related to the nuclear industry, such as books, research papers, articles, journals, etc.

• Ensure the datasets are free for commercial use

Methodologies/Plan of Attack (8 Weeks):

• Weeks 1: Perform research on data and LLMs

• Week 1.5: Gather data

• Week 2: Develop code to run open-source non-fine-tuned LLM

• Weeks 3-5: Data generation for fine-tuning LLM

• Weeks 6-7: Fine-tune LLM

• Week 8: Model evaluation
